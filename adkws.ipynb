{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-Musty/Keyword-Spotting-System/blob/main/adkws.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ga1TaG-enUxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "c-5klkCRBlCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
        "!mkdir -p speech_commands\n",
        "!tar -xzf speech_commands_v0.02.tar.gz -C speech_commands\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvTwSQbsVlrw",
        "outputId": "1b39b9ab-ae05-4d9b-913e-ed72e4563f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-03 14:05:10--  http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.253.118.207, 172.217.194.207, 142.251.10.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.253.118.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2428923189 (2.3G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.02.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   2.26G  22.9MB/s    in 1m 54s  \n",
            "\n",
            "2025-07-03 14:07:05 (20.4 MB/s) - ‘speech_commands_v0.02.tar.gz’ saved [2428923189/2428923189]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Device setup ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE4_j_fSSdeU",
        "outputId": "51bc047c-b6eb-43ea-ae06-89a7002ed102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Constants ---\n",
        "CORE_KEYWORDS = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
        "UNKNOWN_KEYWORDS = ['bed', 'bird', 'cat', 'dog', 'happy', 'house', 'marvin', 'sheila', 'tree', 'wow']\n",
        "SAMPLE_RATE = 16000\n",
        "AUDIO_LENGTH = SAMPLE_RATE  # 1 second\n"
      ],
      "metadata": {
        "id": "87JJRTyNB0_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data loading and MFCC extraction ---\n",
        "class MFCCTransform:\n",
        "    def __call__(self, waveform):\n",
        "        waveform = waveform.numpy().squeeze()\n",
        "        mfcc = librosa.feature.mfcc(\n",
        "            y=waveform,\n",
        "            sr=SAMPLE_RATE,\n",
        "            n_mfcc=40,\n",
        "            n_fft=400,\n",
        "            hop_length=160,\n",
        "            win_length=400\n",
        "        )\n",
        "        return torch.from_numpy(mfcc).float()\n",
        "\n",
        "class SpeechCommandsDataset(Dataset):\n",
        "    def __init__(self, keywords, root_dir='speech_commands', transform=None):\n",
        "        self.keywords = keywords\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.file_list = []\n",
        "        self.labels = []\n",
        "        self.label_to_idx = {label: idx for idx, label in enumerate(keywords)}\n",
        "\n",
        "        for label in keywords:\n",
        "            label_dir = os.path.join(root_dir, label)\n",
        "            if os.path.isdir(label_dir):\n",
        "                for file in os.listdir(label_dir):\n",
        "                    if file.endswith('.wav'):\n",
        "                        self.file_list.append(os.path.join(label_dir, file))\n",
        "                        self.labels.append(self.label_to_idx[label])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.file_list[idx]\n",
        "        label = self.labels[idx]\n",
        "        waveform, sr = torchaudio.load(filepath)\n",
        "        if sr != SAMPLE_RATE:\n",
        "            resampler = torchaudio.transforms.Resample(sr, SAMPLE_RATE)\n",
        "            waveform = resampler(waveform)\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)  # mono\n",
        "        if waveform.shape[1] < AUDIO_LENGTH:\n",
        "            waveform = F.pad(waveform, (0, AUDIO_LENGTH - waveform.shape[1]))\n",
        "        else:\n",
        "            waveform = waveform[:, :AUDIO_LENGTH]\n",
        "\n",
        "        if self.transform:\n",
        "            features = self.transform(waveform)\n",
        "            return features, label\n",
        "        else:\n",
        "            return waveform, label\n",
        "\n",
        "# --- TDResNet7 Encoder (Archit & Lee) ---\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, dilation=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=7,\n",
        "                               stride=stride, padding=3*dilation,\n",
        "                               dilation=dilation, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=7,\n",
        "                               stride=1, padding=3*dilation,\n",
        "                               dilation=dilation, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class TDResNet7(nn.Module):\n",
        "    def __init__(self, input_dim=40, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=7,\n",
        "                               stride=1, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        self.layer1 = self._make_layer(hidden_dim, hidden_dim, stride=1, dilation=1)\n",
        "        self.layer2 = self._make_layer(hidden_dim, hidden_dim, stride=1, dilation=2)\n",
        "        self.layer3 = self._make_layer(hidden_dim, hidden_dim, stride=1, dilation=4)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, stride, dilation):\n",
        "        return ResidualBlock(in_channels, out_channels, stride, dilation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(0)  # batch dim\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool(x)\n",
        "        return x.squeeze(-1)  # (batch, channels)\n"
      ],
      "metadata": {
        "id": "G2VAtRVUBNSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Attention modules ---\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.scale = embed_dim ** -0.5\n",
        "\n",
        "    def forward(self, support_embeddings):\n",
        "        # support_embeddings: (n_way, n_shot, embed_dim)\n",
        "        Q = self.query(support_embeddings)\n",
        "        K = self.key(support_embeddings)\n",
        "        V = self.value(support_embeddings)\n",
        "\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        attended = torch.matmul(attn_weights, V)\n",
        "        refined = attended.mean(dim=1)\n",
        "        return refined, attn_weights\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.query_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.scale = embed_dim ** -0.5\n",
        "\n",
        "    def forward(self, query_embedding, support_prototypes):\n",
        "        # query_embedding: (batch, embed_dim)\n",
        "        # support_prototypes: (n_way, embed_dim)\n",
        "        batch_size = query_embedding.size(0)\n",
        "        Q = self.query_proj(query_embedding).unsqueeze(1)  # (batch,1,embed_dim)\n",
        "        K = self.key_proj(support_prototypes).unsqueeze(0).expand(batch_size, -1, -1)  # (batch,n_way,embed_dim)\n",
        "        V = self.value_proj(support_prototypes).unsqueeze(0).expand(batch_size, -1, -1)\n",
        "\n",
        "        attn_scores = torch.bmm(Q, K.transpose(1, 2)) * self.scale\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        refined_query_prototype = torch.bmm(attn_weights, V).squeeze(1)\n",
        "        return refined_query_prototype, attn_weights\n",
        "\n",
        "# --- Complete Attention Prototypical Network ---\n",
        "class AttentionProtoNet(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.self_attention = SelfAttention(embed_dim=64)\n",
        "        self.cross_attention = CrossAttention(embed_dim=64)\n",
        "\n",
        "    def forward(self, support, query):\n",
        "        # support: (n_way, n_shot, channels, time)\n",
        "        # query: (n_query, channels, time)\n",
        "        n_way, n_shot, C, T = support.shape\n",
        "        n_query = query.shape[0]\n",
        "\n",
        "        support = support.view(n_way * n_shot, C, T)\n",
        "        support_embeds = self.encoder(support).view(n_way, n_shot, -1)  # (n_way,n_shot,embed_dim)\n",
        "        query_embeds = self.encoder(query)  # (n_query, embed_dim)\n",
        "\n",
        "        # Self-attention over support to get refined prototypes\n",
        "        refined_prototypes, _ = self.self_attention(support_embeds)  # (n_way, embed_dim)\n",
        "\n",
        "        # Cross-attention: query-conditioned prototype\n",
        "        query_conditioned_prototypes, _ = self.cross_attention(query_embeds, refined_prototypes)  # (n_query, embed_dim)\n",
        "\n",
        "        # Calculate distances between query embeddings and their respective prototypes\n",
        "        dists = torch.norm(query_embeds - query_conditioned_prototypes, dim=1)  # (n_query)\n",
        "\n",
        "        # We need logits for cross_entropy: shape (n_query, n_way)\n",
        "        # Current dists is (n_query), we must expand for classification over classes:\n",
        "        # We'll compute distances of each query to *all* prototypes, then cross-attend per query.\n",
        "\n",
        "        # Compute distances of each query to each prototype (for classification)\n",
        "        all_dists = torch.cdist(query_embeds, refined_prototypes)  # (n_query, n_way)\n",
        "        log_p_y = F.log_softmax(-all_dists, dim=1)  # probabilities over classes\n",
        "\n",
        "        return log_p_y\n",
        "\n",
        "# --- Episodic sampler ---\n",
        "def create_episode(dataset, n_way, n_shot, n_query):\n",
        "    min_samples = n_shot + n_query\n",
        "    label_to_idx = dataset.label_to_idx\n",
        "\n",
        "    # Filter classes with enough samples\n",
        "    valid_classes = [k for k in dataset.keywords if dataset.labels.count(label_to_idx[k]) >= min_samples]\n",
        "    if len(valid_classes) < n_way:\n",
        "        raise ValueError(f\"Not enough classes with enough samples: {len(valid_classes)} found, need {n_way}\")\n",
        "\n",
        "    classes = random.sample(valid_classes, n_way)\n",
        "\n",
        "    support_samples = []\n",
        "    query_samples = []\n",
        "    query_labels = []\n",
        "\n",
        "    for i, cls in enumerate(classes):\n",
        "        cls_indices = [idx for idx, label in enumerate(dataset.labels) if label == label_to_idx[cls]]\n",
        "        selected = random.sample(cls_indices, min_samples)\n",
        "        support_idxs = selected[:n_shot]\n",
        "        query_idxs = selected[n_shot:]\n",
        "\n",
        "        support_samples.append([dataset[i][0] for i in support_idxs])\n",
        "        query_samples.extend([dataset[i][0] for i in query_idxs])\n",
        "        query_labels.extend([i] * n_query)\n",
        "\n",
        "    support = torch.stack([torch.stack(s) for s in support_samples])\n",
        "    query = torch.stack(query_samples)\n",
        "    labels = torch.tensor(query_labels)\n",
        "\n",
        "    return support, query, labels\n",
        "\n",
        "# --- Training & Evaluation ---\n",
        "def train_epoch(model, optimizer, dataset, n_way, n_shot, n_query, episodes):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    for _ in tqdm(range(episodes)):\n",
        "        support, query, labels = create_episode(dataset, n_way, n_shot, n_query)\n",
        "        support, query, labels = support.to(device), query.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        log_p_y = model(support, query)\n",
        "        loss = F.nll_loss(log_p_y, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = log_p_y.argmax(dim=1)\n",
        "        acc = (preds == labels).float().mean()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += acc.item()\n",
        "    return total_loss / episodes, total_acc / episodes\n",
        "\n",
        "def evaluate(model, dataset, n_way, n_shot, n_query, episodes):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for _ in tqdm(range(episodes)):\n",
        "            support, query, labels = create_episode(dataset, n_way, n_shot, n_query)\n",
        "            support, query, labels = support.to(device), query.to(device), labels.to(device)\n",
        "\n",
        "            log_p_y = model(support, query)\n",
        "            loss = F.nll_loss(log_p_y, labels)\n",
        "\n",
        "            preds = log_p_y.argmax(dim=1)\n",
        "            acc = (preds == labels).float().mean()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_acc += acc.item()\n",
        "    return total_loss / episodes, total_acc / episodes\n",
        "\n",
        "# --- Main Execution ---\n",
        "transform = MFCCTransform()\n",
        "train_dataset = SpeechCommandsDataset(CORE_KEYWORDS[:8], root_dir='speech_commands', transform=transform)\n",
        "val_dataset = SpeechCommandsDataset(CORE_KEYWORDS[8:], root_dir='speech_commands', transform=transform)\n",
        "test_dataset = SpeechCommandsDataset(UNKNOWN_KEYWORDS[:5], root_dir='speech_commands', transform=transform)\n",
        "\n",
        "model = AttentionProtoNet(TDResNet7()).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "n_way, n_shot, n_query = 3, 5, 15\n",
        "train_episodes, val_episodes, test_episodes = 200, 100, 100\n",
        "epochs = 50\n",
        "\n",
        "print(\"Starting initial evaluation on unknown keywords...\")\n",
        "test_loss, test_acc = evaluate(model, test_dataset, n_way, n_shot, n_query, test_episodes)\n",
        "print(f\"Initial Test Loss: {test_loss:.4f} | Initial Test Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
        "\n",
        "# Dynamically adjust val n_way based on available classes in val dataset\n",
        "val_n_way = len(val_dataset.keywords)\n",
        "if val_n_way < n_way:\n",
        "    print(f\"Validation n_way ({val_n_way}) is less than train n_way ({n_way}). Using val_n_way={val_n_way} for validation episodes.\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_epoch(model, optimizer, train_dataset, n_way, n_shot, n_query, train_episodes)\n",
        "    val_loss, val_acc = evaluate(model, val_dataset, val_n_way, n_shot, n_query, val_episodes)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss over Epochs')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_accs, label='Train Acc')\n",
        "plt.plot(val_accs, label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy over Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsGVBySxCeVc",
        "outputId": "366d8c1a-3b51-4105-d969-720cf3229bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting initial evaluation on unknown keywords...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Test Loss: 8.6199 | Initial Test Acc: 33.36%\n",
            "Validation n_way (2) is less than train n_way (3). Using val_n_way=2 for validation episodes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.63it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50: Train Loss: 0.6226, Train Acc: 71.66% | Val Loss: 0.4254, Val Acc: 81.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50: Train Loss: 0.3457, Train Acc: 85.98% | Val Loss: 0.5186, Val Acc: 74.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50: Train Loss: 0.2170, Train Acc: 92.11% | Val Loss: 0.6021, Val Acc: 70.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50: Train Loss: 0.1762, Train Acc: 93.59% | Val Loss: 0.5572, Val Acc: 73.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:59<00:00,  1.68it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50: Train Loss: 0.1782, Train Acc: 93.27% | Val Loss: 0.5715, Val Acc: 71.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50: Train Loss: 0.1418, Train Acc: 94.81% | Val Loss: 0.5269, Val Acc: 75.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:58<00:00,  1.68it/s]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50: Train Loss: 0.1164, Train Acc: 95.81% | Val Loss: 0.5081, Val Acc: 75.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50: Train Loss: 0.1001, Train Acc: 96.36% | Val Loss: 0.4965, Val Acc: 76.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50: Train Loss: 0.1015, Train Acc: 96.21% | Val Loss: 0.5329, Val Acc: 74.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50: Train Loss: 0.1000, Train Acc: 96.22% | Val Loss: 0.4782, Val Acc: 78.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50: Train Loss: 0.0973, Train Acc: 96.38% | Val Loss: 0.3881, Val Acc: 82.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:59<00:00,  1.67it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50: Train Loss: 0.0756, Train Acc: 97.31% | Val Loss: 0.4347, Val Acc: 81.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50: Train Loss: 0.0800, Train Acc: 97.16% | Val Loss: 0.4894, Val Acc: 77.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:59<00:00,  1.67it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50: Train Loss: 0.0731, Train Acc: 97.31% | Val Loss: 0.4335, Val Acc: 79.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50: Train Loss: 0.0785, Train Acc: 97.28% | Val Loss: 0.4194, Val Acc: 80.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50: Train Loss: 0.0677, Train Acc: 97.60% | Val Loss: 0.3812, Val Acc: 83.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50: Train Loss: 0.0627, Train Acc: 97.70% | Val Loss: 0.4611, Val Acc: 78.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:59<00:00,  1.67it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50: Train Loss: 0.0676, Train Acc: 97.56% | Val Loss: 0.4841, Val Acc: 78.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50: Train Loss: 0.0601, Train Acc: 97.77% | Val Loss: 0.3994, Val Acc: 82.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50: Train Loss: 0.0628, Train Acc: 97.80% | Val Loss: 0.4434, Val Acc: 81.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.63it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50: Train Loss: 0.0527, Train Acc: 98.12% | Val Loss: 0.3461, Val Acc: 85.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:39<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50: Train Loss: 0.0545, Train Acc: 97.84% | Val Loss: 0.4451, Val Acc: 81.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50: Train Loss: 0.0579, Train Acc: 97.76% | Val Loss: 0.3620, Val Acc: 84.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50: Train Loss: 0.0535, Train Acc: 97.89% | Val Loss: 0.5872, Val Acc: 72.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50: Train Loss: 0.0621, Train Acc: 97.67% | Val Loss: 0.5126, Val Acc: 77.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50: Train Loss: 0.0560, Train Acc: 97.86% | Val Loss: 0.4906, Val Acc: 77.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:03<00:00,  1.62it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50: Train Loss: 0.0539, Train Acc: 97.99% | Val Loss: 0.4902, Val Acc: 77.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:03<00:00,  1.62it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50: Train Loss: 0.0441, Train Acc: 98.33% | Val Loss: 0.4383, Val Acc: 80.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:03<00:00,  1.61it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50: Train Loss: 0.0473, Train Acc: 98.29% | Val Loss: 0.4769, Val Acc: 78.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:59<00:00,  1.67it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50: Train Loss: 0.0576, Train Acc: 97.93% | Val Loss: 0.4684, Val Acc: 79.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50: Train Loss: 0.0497, Train Acc: 98.11% | Val Loss: 0.3867, Val Acc: 84.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50: Train Loss: 0.0481, Train Acc: 98.11% | Val Loss: 0.3872, Val Acc: 83.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.63it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50: Train Loss: 0.0462, Train Acc: 98.26% | Val Loss: 0.3608, Val Acc: 84.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50: Train Loss: 0.0505, Train Acc: 98.10% | Val Loss: 0.4478, Val Acc: 79.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50: Train Loss: 0.0419, Train Acc: 98.50% | Val Loss: 0.5266, Val Acc: 76.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:02<00:00,  1.64it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50: Train Loss: 0.0394, Train Acc: 98.68% | Val Loss: 0.4673, Val Acc: 77.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:00<00:00,  1.66it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50: Train Loss: 0.0353, Train Acc: 98.73% | Val Loss: 0.4751, Val Acc: 77.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [02:01<00:00,  1.65it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50: Train Loss: 0.0482, Train Acc: 98.33% | Val Loss: 0.5575, Val Acc: 75.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 174/200 [01:44<00:14,  1.79it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHr3o6WguJ1OQh7074zxnw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}